{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense   ########## Hidden Layer/ Output Layers for representing your hidden layes / Output Layes\n",
    "# we call dense from tensorflow \n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Dense  ## When we wanted to add hideen layers and output layers in NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense ### I am bringing hidden latyer where leanring with happen in tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential  # Loading bcz we are buiding the model with Sequential approach \n",
    "from tensorflow.keras.layers import Dense  # Hidden Layers \n",
    "\n",
    "\n",
    "\n",
    "# What i need to develop very simple NN with 2 Hidden , 1 Outout , Input Data\n",
    "\n",
    "# Input Data \n",
    "# 2 Hidden Layers \n",
    "# 1 Outoutput \n",
    "# Hidden Layers - Activation \n",
    "# I need to pass my input \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential() ## initializing my Sequential model here in the notebook \n",
    "\n",
    "\n",
    "# Add method on Seuqntial to add different components of NN \n",
    "\n",
    "\n",
    "model.add(Dense(4, input_dim=3, activation='relu' ))  # Input data  , Aasigning hidden layers , applying activaton # Default Intitlizer\n",
    "#Default Intitializer to intilize weights and biase \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(5, activation='relu'))  # Input data  , Aasigning hidden layers , applying activaton  ## Hidden Layer 2 \n",
    "\n",
    "# model.add(Dense(3, activation='relu'))  # Input data  , Aasigning hidden layers , applying activaton \n",
    "\n",
    "#  by this one call, we added two layers. First one is the input layer with two neurons, and the second one is the hidden layer with three neurons.\n",
    "\n",
    "model.add(Dense(2, activation='softmax')) #we are not using input_dim parameter one layer will be added  #Last layer so it will be Output layer too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 12        \n",
      "=================================================================\n",
      "Total params: 53\n",
      "Trainable params: 53\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "input_layer = Input(shape=(3,))\n",
    "\n",
    "model = Dense(4, activation='relu')(input_layer) # H1\n",
    "\n",
    "model = Dense(10, activation='relu')(model) # H2\n",
    "\n",
    "\n",
    "model = Dense(1, activation='softmax')(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model sub-classing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customization can be done\n",
    "# OOPs \n",
    "# Object Orienstedd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model ## Subclass API - Model OWN \n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class SimpleNeuralNetwork(Model):\n",
    "   \n",
    "  # Define all our layers \n",
    "  def __init__(self):\n",
    "    super(SimpleNeuralNetwork, self).__init__()\n",
    "    self.layer1 = Dense(2, activation='relu')\n",
    "    self.layer2 = Dense(3, activation='relu')\n",
    "    self.outputLayer = Dense(1, activation='softmax')\n",
    "\n",
    "  # Execuete NN   \n",
    "  def call(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    return self.outputLayer(x)\n",
    "  \n",
    "model = SimpleNeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential API is the easiest way to implement but comes with certain limitations. \n",
    "##### we canâ€™t create a model that shares feature information to another layer except to its subsequent layer.\n",
    "##### In addition, multiple input and output are not possible to implement either"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
