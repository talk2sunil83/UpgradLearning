# -*- coding: utf-8 -*-
"""TF2.0 Linear Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16kgx8sv9v3dunBeMc_Db4YzAUFkziA1_
"""

# Commented out IPython magic to ensure Python compatibility.
# Install TensorFlow
# %%

import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_breast_cancer
import tensorflow as tf
print(tf.__version__)
# %%

# Load in the data
# %%

# load the data
data = load_breast_cancer()
# %%

# check the type of 'data'
type(data)
# %%

# note: it is a Bunch object
# this basically acts like a dictionary where you can treat the keys like attributes
data.keys()
# %%

# 'data' (the attribute) means the input data
data.data.shape
# it has 569 samples, 30 features
# %%

# 'targets'
data.target
# note how the targets are just 0s and 1s
# normally, when you have K targets, they are labeled 0..K-1
# %%

# their meaning is not lost
data.target_names

# %%
# there are also 569 corresponding targets
data.target.shape

# %%
# you can also determine the meaning of each feature
data.feature_names

# %%
# normally we would put all of our imports at the top
# but this lets us tell a story


# %%
# split the data into train and test sets
# this lets us simulate how our model will perform in the future
X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)
N, D = X_train.shape

# %%
# Scale the data
# you'll learn why scaling is needed in a later course

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# %%
# Now all the fun Tensorflow stuff
# Build the model

model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(D,)),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Alternatively, you can do:
# model = tf.keras.models.Sequential()
# model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))

# %%
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# %%

# Train the model
r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)

# %%

# Evaluate the model - evaluate() returns loss and accuracy
print("Train score:", model.evaluate(X_train, y_train))
print("Test score:", model.evaluate(X_test, y_test))

# %%
# Plot what's returned by model.fit()
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')
plt.legend()

# Plot the accuracy too
plt.plot(r.history['accuracy'], label='acc')
plt.plot(r.history['val_accuracy'], label='val_acc')
plt.legend()

# %% [markdown]
"""# Part 2: Making Predictions

This goes with the lecture "Making Predictions"
"""
# %%

# Make predictions
P = model.predict(X_test)
print(P)  # they are outputs of the sigmoid, interpreted as probabilities p(y = 1 | x)

# %%
# Round to get the actual predictions
# Note: has to be flattened since the targets are size (N,) while the predictions are size (N,1)
P = np.round(P).flatten()
print(P)
# %%

# Calculate the accuracy, compare it to evaluate() output
print("Manually calculated accuracy:", np.mean(P == y_test))
print("Evaluate output:", model.evaluate(X_test, y_test))

# %% [markdown]
"""# Part 3: Saving and Loading a Model

This goes with the lecture "Saving and Loading a Model"
"""
# %%

# Let's now save our model to a file
model.save('linearclassifier.h5')

# %%

# Let's load the model and confirm that it still works
# Note: there is a bug in Keras where load/save only works if you DON'T use the Input() layer explicitly
# So, make sure you define the model with ONLY Dense(1, input_shape=(D,))
# At least, until the bug is fixed
# https://github.com/keras-team/keras/issues/10417
model = tf.keras.models.load_model('linearclassifier.h5')
print(model.layers)
model.evaluate(X_test, y_test)

# # Download the file - requires Chrome (at this point)
# from google.colab import files
# files.download('linearclassifier.h5')
