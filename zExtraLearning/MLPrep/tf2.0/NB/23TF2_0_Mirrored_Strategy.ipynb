{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0 Mirrored Strategy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz_OP9V5Ah_C",
        "outputId": "47313d1b-ce83-41ff-faf0-edf2efef6f7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow 2.x selected.\n",
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCdSfLYrU_63"
      },
      "source": [
        "# additional imports\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2crnNg7V6if",
        "outputId": "d04c47e5-437d-460a-d6b0-d5c12d49503a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Load in the data\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "print(\"x_train.shape:\", x_train.shape)\n",
        "print(\"y_train.shape\", y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape: (50000, 32, 32, 3)\n",
            "y_train.shape (50000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJKvgsz2V8Z6",
        "outputId": "1642ee89-70b6-49cd-e277-783df5ddf476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# number of classes\n",
        "K = len(set(y_train))\n",
        "print(\"number of classes:\", K)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qq3d-yAWBwy"
      },
      "source": [
        "# Build the model using the functional API\n",
        "def create_model():\n",
        "  i = Input(shape=x_train[0].shape)\n",
        "\n",
        "  x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "  model = Model(i, x)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY6FtNwMWHvL"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "# strategy = tf.distribute.experimental.CentralStorageStrategy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsBCFF7rWLkL",
        "outputId": "4301e9c4-93be-4759-bf84-4821c73c707e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'Number of devices: {strategy.num_replicas_in_sync}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEypaMmBWSX2"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoi8UWuOWx-2",
        "outputId": "23adbf4b-6ba6-417f-e792-12cd49658754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "# Fit\n",
        "r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0811 18:03:54.175649 140429139875584 deprecation.py:323] From /tensorflow-2.0.0b1/python3.6/tensorflow/python/keras/layers/normalization.py:457: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1563 steps, validate on 313 steps\n",
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 23s 14ms/step - loss: 1.3045 - accuracy: 0.5541 - val_loss: 0.9532 - val_accuracy: 0.6640\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.8394 - accuracy: 0.7093 - val_loss: 0.8020 - val_accuracy: 0.7339\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.6854 - accuracy: 0.7643 - val_loss: 0.8026 - val_accuracy: 0.7286\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.5819 - accuracy: 0.8012 - val_loss: 0.6905 - val_accuracy: 0.7778\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4859 - accuracy: 0.8322 - val_loss: 0.6967 - val_accuracy: 0.7767\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.4108 - accuracy: 0.8567 - val_loss: 0.6145 - val_accuracy: 0.8024\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.3517 - accuracy: 0.8768 - val_loss: 0.6851 - val_accuracy: 0.7975\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2934 - accuracy: 0.8977 - val_loss: 0.6551 - val_accuracy: 0.8104\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2536 - accuracy: 0.9132 - val_loss: 0.6276 - val_accuracy: 0.8251\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.2205 - accuracy: 0.9224 - val_loss: 0.6870 - val_accuracy: 0.8156\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1921 - accuracy: 0.9327 - val_loss: 0.7153 - val_accuracy: 0.8161\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 0.1732 - accuracy: 0.9413 - val_loss: 0.6962 - val_accuracy: 0.8218\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1587 - accuracy: 0.9458 - val_loss: 0.7655 - val_accuracy: 0.8200\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1512 - accuracy: 0.9505 - val_loss: 0.8894 - val_accuracy: 0.8010\n",
            "Epoch 15/15\n",
            "1556/1563 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9550"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0811 18:07:53.185556 140432385251200 training_arrays.py:309] Your dataset ran out of data; interrupting training. Make sure that your dataset can generate at least `steps_per_epoch * epochs` batches (in this case, 23445 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR4wx7xOZsb4",
        "outputId": "0da29397-1c0f-45fd-da33-e8f251f20a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "50000/391"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127.8772378516624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f74dSFbDZ_qD",
        "outputId": "8bbbd5a7-2f08-4063-8de0-3641319b7caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "10000/79"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "126.58227848101266"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyqgOWC9NOTv",
        "outputId": "0c322ad8-be47-4fcf-b8e1-63eee185d99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Compare this to non-distributed training\n",
        "model2 = create_model()\n",
        "model2.compile(loss='sparse_categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "r = model2.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 25s 502us/sample - loss: 1.3957 - accuracy: 0.5369 - val_loss: 1.0386 - val_accuracy: 0.6328\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 23s 465us/sample - loss: 0.8563 - accuracy: 0.7029 - val_loss: 0.8461 - val_accuracy: 0.7063\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 24s 471us/sample - loss: 0.7013 - accuracy: 0.7592 - val_loss: 0.8004 - val_accuracy: 0.7334\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 24s 473us/sample - loss: 0.5897 - accuracy: 0.7959 - val_loss: 0.6652 - val_accuracy: 0.7788\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 24s 471us/sample - loss: 0.5054 - accuracy: 0.8267 - val_loss: 0.6899 - val_accuracy: 0.7758\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}